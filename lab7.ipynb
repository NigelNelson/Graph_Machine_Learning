{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI_oiMZPEF4W"
      },
      "source": [
        "## Loading Graphs from CSV\n",
        "\n",
        "Jay Urbain, PhD\n",
        "\n",
        "1/24/2023\n",
        "\n",
        "Credits: https://pytorch-geometric.readthedocs.io/en/latest/notes/load_csv.html (only small modifications).\n",
        "\n",
        "In this example, we will show how to load a set of *.csv files as input and construct a heterogeneous graph from it, which can be used as input to a heterogeneous graph model. This tutorial is also available as an executable example script in the examples/hetero directory.\n",
        "\n",
        "We are going to use the MovieLens dataset collected by the GroupLens research group. This toy dataset describes 5-star rating and tagging activity from MovieLens. The dataset contains approximately 100k ratings across more than 9k movies from more than 600 users. We are going to use this dataset to generate two node types holding data for movies and users, respectively, and one edge type connecting users and movies, representing the relation of how a user has rated a specific movie.\n",
        "\n",
        "First, we download the dataset to an arbitrary folder (in this case, the current directory):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7kERHKUFqcB"
      },
      "outputs": [],
      "source": [
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z02QjGyFEBhB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nelsonni\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting .\\ml-latest-small.zip\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.data import download_url, extract_zip\n",
        "\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfvZXy65EXGn"
      },
      "source": [
        "Before we create the heterogeneous graph, letâ€™s take a look at the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sSgJ4nFgEMa4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId                               title  \\\n",
              "0        1                    Toy Story (1995)   \n",
              "1        2                      Jumanji (1995)   \n",
              "2        3             Grumpier Old Men (1995)   \n",
              "3        4            Waiting to Exhale (1995)   \n",
              "4        5  Father of the Bride Part II (1995)   \n",
              "\n",
              "                                        genres  \n",
              "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "1                   Adventure|Children|Fantasy  \n",
              "2                               Comedy|Romance  \n",
              "3                         Comedy|Drama|Romance  \n",
              "4                                       Comedy  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.read_csv(movie_path).head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7dmOZ_8SGIOb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.read_csv(rating_path).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZwec4sfEcZI"
      },
      "source": [
        "We see that the `movies.csv` file provides three columns: movieId assigns a unique identifier to each movie, while the title and genres columns represent title and genres of the given movie. We can make use of those two columns to define a feature representation that can be easily interpreted by machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVjnx3bUEiqZ"
      },
      "source": [
        "The `ratings.csv` data connects users (as given by userId) and movies (as given by movieId), and defines how a given user has rated a specific movie (rating). For simplicity, we do not make use of the additional timestamp information.\n",
        "\n",
        "For representing this data in the PyG data format, we first define a method load_node_csv() that reads in a `*.csv` file and returns a node-level feature representation `x` of shape [num_nodes, num_features]:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i7zTSukdEjmM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def load_node_csv(path, index_col, encoders=None, **kwargs):\n",
        "    df = pd.read_csv(path, index_col=index_col, **kwargs)\n",
        "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
        "\n",
        "    x = None\n",
        "    if encoders is not None:\n",
        "        xs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
        "        x = torch.cat(xs, dim=-1)\n",
        "\n",
        "    return x, mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zP_weiOEnCM"
      },
      "source": [
        "Here, `load_node_csv()` reads the `*.csv` file from path, and creates a dictionary mapping that maps its index column to a consecutive value in the range `{ 0, ..., num_rows - 1 }`. This is needed as we want our final data representation to be as compact as possible, e.g., the representation of a movie in the first row should be accessible via `x[0]`.\n",
        "\n",
        "We further utilize the concept of encoders, which define how the values of specific columns should be encoded into a numerical feature representation. For example, we can define a sentence encoder that encodes raw column strings into low-dimensional embeddings. For this, we make use of the excellent `sentence-transformers` library which provides a large number of state-of-the-art pretrained NLP embedding models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "os-tQWXvEpGp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "Requirement already satisfied: tqdm in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: torchvision in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentence-transformers) (1.9.3)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-win_amd64.whl (1.1 MB)\n",
            "Collecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (22.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-win_amd64.whl (3.3 MB)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2022.10.31-cp38-cp38-win_amd64.whl (267 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: joblib in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: click in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py): started\n",
            "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125956 sha256=51585d3ef2352044da83058f489b192c09b6ab47ffddcd13874e3dcf2ddf7798\n",
            "  Stored in directory: c:\\users\\nelsonni\\appdata\\local\\pip\\cache\\wheels\\5e\\6f\\8c\\d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, filelock, tokenizers, regex, huggingface-hub, transformers, sentencepiece, nltk, sentence-transformers\n",
            "Successfully installed filelock-3.9.0 huggingface-hub-0.11.1 nltk-3.8.1 pyyaml-6.0 regex-2022.10.31 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the 'c:\\users\\nelsonni\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VMkFn9lAErUC"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class SequenceEncoder(object):\n",
        "    def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n",
        "        self.device = device\n",
        "        self.model = SentenceTransformer(model_name, device=device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(self, df):\n",
        "        x = self.model.encode(df.values, show_progress_bar=True,\n",
        "                              convert_to_tensor=True, device=self.device)\n",
        "        return x.cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfSUoS9XEttq"
      },
      "source": [
        "The `SequenceEncoder` class loads a pre-trained NLP model as given by model_name, and uses it to encode a list of strings into a PyTorch tensor of shape `[num_strings, embedding_dim]`. We can use this SequenceEncoder to encode the title of the movies.csv file.\n",
        "\n",
        "In a similar fashion, we can create another encoder that converts the genres of movies, e.g., Adventure|Children|Fantasy, into categorical labels. For this, we first need to find all existing genres present in the data, create a feature representation x of shape `[num_movies, num_genres]`, and assign a 1 to `x[i, j]` in case the genre j is present in movie i:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PUNUGp9yEvni"
      },
      "outputs": [],
      "source": [
        "class GenresEncoder(object):\n",
        "    def __init__(self, sep='|'):\n",
        "        self.sep = sep\n",
        "\n",
        "    def __call__(self, df):\n",
        "        genres = set(g for col in df.values for g in col.split(self.sep))\n",
        "        mapping = {genre: i for i, genre in enumerate(genres)}\n",
        "\n",
        "        x = torch.zeros(len(df), len(mapping))\n",
        "        for i, col in enumerate(df.values):\n",
        "            for genre in col.split(self.sep):\n",
        "                x[i, mapping[genre]] = 1\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IPRFY-NExhS"
      },
      "source": [
        "With this, we can obtain our final representation of movies via:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gBWoRXqhEyKL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.18k/1.18k [00:00<00:00, 184kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:00<00:00, 62.6kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.6k/10.6k [00:00<00:00, 3.03MB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 612/612 [00:00<00:00, 112kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 27.8kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39.3k/39.3k [00:00<00:00, 732kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90.9M/90.9M [00:02<00:00, 30.7MB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53.0/53.0 [00:00<00:00, 26.1kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112/112 [00:00<00:00, 25.8kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 2.81MB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 350/350 [00:00<00:00, 117kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.2k/13.2k [00:00<00:00, 519kB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 1.92MB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 349/349 [00:00<00:00, 91.9kB/s]\n",
            "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [00:30<00:00,  9.87it/s]\n"
          ]
        }
      ],
      "source": [
        "movie_x, movie_mapping = load_node_csv(movie_path, index_col='movieId', encoders={'title': SequenceEncoder(),\n",
        "        'genres': GenresEncoder()\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjwVHBDxE1VU"
      },
      "source": [
        "Similarly, we can utilize `load_node_csv()` for obtaining a user mapping from userId to consecutive values as well. However, there is no additional feature information for users present in this dataset. As such, we do not define any encoders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aBN6-oiSE2vq"
      },
      "outputs": [],
      "source": [
        "_, user_mapping = load_node_csv(rating_path, index_col='userId')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL3TuxF6E56c"
      },
      "source": [
        "With this, we are ready to initialize our HeteroData object and pass two node types into it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OOSI10jzE60x"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HeteroData(\n",
            "  \u001b[1muser\u001b[0m={ num_nodes=610 },\n",
            "  \u001b[1mmovie\u001b[0m={ x=[9742, 404] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "data = HeteroData()\n",
        "\n",
        "data['user'].num_nodes = len(user_mapping)  # Users do not have any features.\n",
        "data['movie'].x = movie_x\n",
        "\n",
        "print(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us9IweJLE-BO"
      },
      "source": [
        "As users do not have any node-level information, we solely define its number of nodes. As a result, we likely need to learn distinct user embeddings via torch.nn.Embedding in an end-to-end fashion during training of a heterogeneous graph model.\n",
        "\n",
        "Next, we take a look at connecting users with movies as defined by their ratings. For this, we define a method load_edge_csv() that returns the final edge_index representation of shape [2, num_ratings] from ratings.csv, as well as any additional features present in the raw *.csv file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HE46Urv6E_9T"
      },
      "outputs": [],
      "source": [
        "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping,\n",
        "                  encoders=None, **kwargs):\n",
        "    df = pd.read_csv(path, **kwargs)\n",
        "\n",
        "    src = [src_mapping[index] for index in df[src_index_col]]\n",
        "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
        "    edge_index = torch.tensor([src, dst])\n",
        "\n",
        "    edge_attr = None\n",
        "    if encoders is not None:\n",
        "        edge_attrs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
        "        edge_attr = torch.cat(edge_attrs, dim=-1)\n",
        "\n",
        "    return edge_index, edge_attr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_Ri3VnqFDAS"
      },
      "source": [
        "Here, src_index_col and dst_index_col define the index columns of source and destination nodes, respectively. We further make use of the node-level mappings src_mapping and dst_mapping to ensure that raw indices are mapped to the correct consecutive indices in our final representation. For every edge defined in the file, it looks up the forward indices in src_mapping and dst_mapping, and moves the data appropriately.\n",
        "\n",
        "Similarly to load_node_csv(), encoders are used to return additional edge-level feature information. For example, for loading the ratings from the rating column in ratings.csv, we can define an IdentityEncoder that simply converts a list of floating-point values into a PyTorch tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XuGgP9DqFDtJ"
      },
      "outputs": [],
      "source": [
        "class IdentityEncoder(object):\n",
        "    def __init__(self, dtype=None):\n",
        "        self.dtype = dtype\n",
        "\n",
        "    def __call__(self, df):\n",
        "        return torch.from_numpy(df.values).view(-1, 1).to(self.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLrjBjkXFGI5"
      },
      "source": [
        "With this, we are ready to finalize our HeteroData object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2ORUD5mvFJH3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HeteroData(\n",
            "  \u001b[1muser\u001b[0m={ num_nodes=610 },\n",
            "  \u001b[1mmovie\u001b[0m={ x=[9742, 404] },\n",
            "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
            "    edge_index=[2, 100836],\n",
            "    edge_label=[100836, 1]\n",
            "  }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "edge_index, edge_label = load_edge_csv(\n",
        "    rating_path,\n",
        "    src_index_col='userId',\n",
        "    src_mapping=user_mapping,\n",
        "    dst_index_col='movieId',\n",
        "    dst_mapping=movie_mapping,\n",
        "    encoders={'rating': IdentityEncoder(dtype=torch.long)},\n",
        ")\n",
        "\n",
        "data['user', 'rates', 'movie'].edge_index = edge_index\n",
        "data['user', 'rates', 'movie'].edge_label = edge_label\n",
        "\n",
        "print(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO7Y_f9oFLJg"
      },
      "source": [
        "This HeteroData object is the native format of heterogeneous graphs in PyG and can be used as input for heterogeneous graph models."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "ed267233ffaff722c00ae660dc6e05de3bc5a802c9306c6c76dc3482fc10ff8d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
